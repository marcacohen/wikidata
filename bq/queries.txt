SELECT * FROM `bigquery-public-data.wikipedia.view_gcs` LIMIT 10

SELECT *, _FILE_NAME fn FROM `bigquery-public-data.wikipedia.view_gcs` LIMIT 10

SELECT COUNT(*) rs 
FROM `bigquery-public-data.wikipedia.view_gcs` 
WHERE _FILE_NAME = 
  'gs://wiki-staging/dumps.wikimedia.org/other/pageviews/2015/2015-05/pageviews-20150501-010000.gz'

#standardSQL
CREATE VIEW `bigquery-public-data.wikipedia.view_parsed`
AS SELECT
  PARSE_TIMESTAMP('%Y%m%d-%H%M%S', REGEXP_EXTRACT(_FILE_NAME, '([0-9]+-[0-9]+).gz$')) datehour
  , REGEXP_EXTRACT(line, '([^ ]*) ') wiki
  , REGEXP_EXTRACT(line, '[^ ]* (.*) [0-9]+ [0-9]+') title
  , CAST(REGEXP_EXTRACT(line, ' ([0-9]+) [0-9]+$') AS INT64) views
  , CAST(REGEXP_EXTRACT(line, ' ([0-9]+)$') AS INT64) zero
  , _FILE_NAME filename
  , line
FROM `bigquery-public-data.wikipedia.view_gcs`WHERE REGEXP_EXTRACT(line, ' ([0-9]+) [0-9]+$') IS NOT NULL # views
AND REGEXP_EXTRACT(line, ' ([0-9]+)$') = '0'

#standardSQL 
SELECT * 
FROM `bigquery-public-data.wikipedia.view_parsed` 
LIMIT 10

#standardSQL
SELECT COUNT(*) n_rows, SUM(views) views
  , ARRAY_AGG(DISTINCT filename) files
FROM `bigquery-public-data.wikipedia.view_parsed`
WHERE EXTRACT(YEAR FROM datehour)=2015
AND EXTRACT(MONTH FROM datehour)=10
AND EXTRACT(DAY FROM datehour)=21
AND EXTRACT(HOUR FROM datehour)=7

CREATE TABLE `bigquery-public-data.wikipedia.pageviews_2015`
 (datehour TIMESTAMP, wiki STRING, title STRING, views INT64)
 PARTITION BY DATE(datehour)
 CLUSTER BY wiki, title
 OPTIONS(
   description = 'Wikipedia pageviews from http://dumps.wikimedia.your.org/other/pageviews/, partitioned by date, clustered by (wiki, title)',
   require_partition_filter = true
 )
 AS SELECT datehour, wiki, SUBSTR(title, 0, 300) title, views
 FROM `bigquery-public-data.wikipedia.view_parsed` t1
 WHERE BYTE_LENGTH(wiki)+ BYTE_LENGTH(title) < 1024
 AND BYTE_LENGTH(title) < 300
 AND EXTRACT(YEAR FROM datehour)=2015

CREATE TEMP FUNCTION parse(item STRING)
RETURNS STRUCT <
  id STRING
  ,numeric_id INT64
  ,en_label STRING
  ,en_wiki STRING
  ,en_description STRING
  ,ja_label STRING
  ,ja_wiki STRING
  ,ja_description STRING
  ,es_label STRING
  ,es_wiki STRING
  ,es_description STRING
  ,fr_label STRING
  ,fr_wiki STRING
  ,fr_description STRING  
  ,de_label STRING
  ,de_wiki STRING
  ,de_description STRING
  ,type STRING
  ,sitelinks ARRAY<STRUCT<site STRING, title STRING, encoded STRING>>
  ,descriptions ARRAY<STRUCT<language STRING, value STRING>>
  ,labels ARRAY<STRUCT<language STRING, value STRING>>
  ,aliases ARRAY<STRUCT<language STRING, value STRING>>
  ,instance_of ARRAY<STRUCT<numeric_id INT64>>
  ,gender ARRAY<STRUCT<numeric_id INT64>>
  ,date_of_birth ARRAY<STRUCT<time STRING>>
  ,date_of_death ARRAY<STRUCT<time STRING>>
  ,place_of_birth ARRAY<STRUCT<numeric_id INT64>>
  ,country_of_citizenship ARRAY<STRUCT<numeric_id INT64>>
  ,country ARRAY<STRUCT<numeric_id INT64>>
  ,occupation ARRAY<STRUCT<numeric_id INT64>>
  ,instrument ARRAY<STRUCT<numeric_id INT64>>
  ,genre ARRAY<STRUCT<numeric_id INT64>>
  ,industry ARRAY<STRUCT<numeric_id INT64>>
  ,subclass_of ARRAY<STRUCT<numeric_id INT64>>
  ,coordinate_location ARRAY<STRUCT<latitude FLOAT64, longitude FLOAT64>>
  ,iso_3166_alpha3 ARRAY<STRUCT<value STRING>> 
  ,member_of ARRAY<STRUCT<numeric_id INT64>> 
  ,from_fictional_universe ARRAY<STRUCT<numeric_id INT64>> 
>

LANGUAGE js AS """
  function wikiEncode(x) {
    return x ? (x.split(' ').join('_')) : null;
  }
  
  var obj = JSON.parse(item.replace(/,$/, ''));
  sitelinks =[];
  for(var i in obj.sitelinks) {
    sitelinks.push({'site':obj.sitelinks[i].site, 'title':obj.sitelinks[i].title, 'encoded':wikiEncode(obj.sitelinks[i].title)}) 
  }  
  descriptions =[];
  for(var i in obj.descriptions) {
    descriptions.push({'language':obj.descriptions[i].language, 'value':obj.descriptions[i].value}) 
  }
  labels =[];
  for(var i in obj.labels) {
    labels.push({'language':obj.labels[i].language, 'value':obj.labels[i].value}) 
  }
  aliases =[];
  for(var i in obj.aliases) {
    for(var j in obj.aliases[i]) {
      aliases.push({'language':obj.aliases[i][j].language, 'value':obj.aliases[i][j].value}) 
    }
  }
  
  function snaks(obj, pnumber, name) {
    var snaks = []
    for(var i in obj.claims[pnumber]) {
      if (!obj.claims[pnumber][i].mainsnak.datavalue) continue;
      var claim = {}
      claim[name]=obj.claims[pnumber][i].mainsnak.datavalue.value[name.split('_').join('-')]
      snaks.push(claim) 
    }
    return snaks
  }
  function snaksValue(obj, pnumber, name) {
    var snaks = []
    for(var i in obj.claims[pnumber]) {
      if (!obj.claims[pnumber][i].mainsnak.datavalue) continue;
      var claim = {}
      claim[name]=obj.claims[pnumber][i].mainsnak.datavalue.value
      snaks.push(claim) 
    }
    return snaks
  }
  function snaksLoc(obj, pnumber) {
    var snaks = []
    for(var i in obj.claims[pnumber]) {
      if (!obj.claims[pnumber][i].mainsnak.datavalue) continue;
      var claim = {}
      claim['longitude']=obj.claims[pnumber][i].mainsnak.datavalue.value['longitude']
      claim['latitude']=obj.claims[pnumber][i].mainsnak.datavalue.value['latitude']
      snaks.push(claim) 
    }
    return snaks
  }
  function snaksNum(obj, pnumber) {
    return snaks(obj, pnumber, 'numeric_id');
  }
  
  return {
    id: obj.id,
    numeric_id: parseInt(obj.id.substr(1)),
    en_wiki: obj.sitelinks ? (obj.sitelinks.enwiki ? wikiEncode(obj.sitelinks.enwiki.title) : null) : null,
    en_label: obj.labels.en ? obj.labels.en.value : null,
    en_description: obj.descriptions.en ? obj.descriptions.en.value : null,
    ja_wiki: obj.sitelinks ? (obj.sitelinks.jawiki ? wikiEncode(obj.sitelinks.jawiki.title) : null) : null,
    ja_label: obj.labels.ja ? obj.labels.ja.value : null,
    ja_description: obj.descriptions.ja ? obj.descriptions.ja.value : null,
    es_wiki: obj.sitelinks ? (obj.sitelinks.eswiki ? wikiEncode(obj.sitelinks.eswiki.title) : null) : null,
    es_label: obj.labels.es ? obj.labels.es.value : null,
    es_description: obj.descriptions.es ? obj.descriptions.es.value : null,
    de_wiki: obj.sitelinks ? (obj.sitelinks.dewiki ? wikiEncode(obj.sitelinks.dewiki.title) : null) : null,
    de_label: obj.labels.de ? obj.labels.de.value : null,
    de_description: obj.descriptions.de ? obj.descriptions.de.value : null,
    
    type: obj.type,
    labels: labels, 
    descriptions: descriptions,
    sitelinks: sitelinks,
    aliases: aliases,
    instance_of: snaksNum(obj, 'P31'),
    gender: snaksNum(obj, 'P21'),
    date_of_birth: snaks(obj, 'P569', 'time'),
    date_of_death: snaks(obj, 'P569', 'time'),
    place_of_birth: snaksNum(obj, 'P19'),
    country_of_citizenship: snaksNum(obj, 'P27'),
    country: snaksNum(obj, 'P17'),
    occupation: snaksNum(obj, 'P106'),
    instrument: snaksNum(obj, 'P1303'),
    genre: snaksNum(obj, 'P136'),
    industry: snaksNum(obj, 'P452'),
    subclass_of: snaksNum(obj, 'P279'),
    coordinate_location: snaksLoc(obj, 'P625'),
    iso_3166_alpha3: snaksValue(obj, 'P298', 'value'),
    member_of: snaksNum(obj, 'P463'),
    from_fictional_universe: snaksNum(obj, 'P1080'),
  }
""";

CREATE OR REPLACE TABLE `bigquery-public-data.wikipedia.wikidata`
PARTITION BY fake_date
CLUSTER BY numeric_id
AS

SELECT parse(item).*, item, DATE('2000-01-01') fake_date
FROM `bigquery-public-data-staging.wikidata.latest_raw`    
WHERE LENGTH(item)>10
AND (
  JSON_EXTRACT_SCALAR(item, '$.sitelinks.enwiki.title') IS NOT NULL
  OR
  JSON_EXTRACT_SCALAR(item, '$.sitelinks.jawiki.title') IS NOT NULL
  OR
  JSON_EXTRACT_SCALAR(item, '$.sitelinks.eswiki.title') IS NOT NULL
  OR
  JSON_EXTRACT_SCALAR(item, '$.labels.en.value') IS NOT NULL
)

SELECT SUM(views) views, title
FROM `bigquery-public-data.wikipedia.pageviews_2015` a
JOIN (
  SELECT DISTINCT en_wiki 
  FROM `bigquery-public-data.wikipedia.wikidata`  
  WHERE EXISTS (SELECT * FROM UNNEST(instance_of) WHERE numeric_id=188784)
  AND en_wiki IS NOT null
) b
ON a.title=b.en_wiki
AND a.wiki='en'
AND DATE(a.datehour) BETWEEN '2015-09-15' AND '2015-09-18'
GROUP BY title
ORDER BY views DESC
LIMIT 10

SELECT title, SUM(views) views
FROM `bigquery-public-data.wikipedia.pageviews_2019`
WHERE
  EXTRACT(YEAR FROM datehour)=2019
  AND REGEXP_CONTAINS(title, '(oogle|acebook)')
GROUP BY title
ORDER BY views DESC

#standardSQL
SELECT datehour, title, views
FROM `bigquery-public-data.wikipedia.pageviews_2019`
WHERE DATE(datehour) BETWEEN "2019-01-01" AND "2019-11-01"
AND wiki = 'en'AND title IN ('The_Beatles', 'The_Rolling_Stones')
